{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen\n",
    "\n",
    "config_list = {\n",
    "    'model': 'llama3.1',\n",
    "    'base_url': 'http://localhost:11434/v1',\n",
    "    'api_key': 'ollama',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redaction Level 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_assistant = autogen.ConversableAgent(\n",
    "    'assistant', \n",
    "    system_message='OBJECTIVE: You are an agent designed to redact personal information from any text provided to you.\\n' \n",
    "                   'Your task is to identify and encapsulate any personal information with stars (*).\\n'\n",
    "                   'IMPORTANT: This includes this list [Names, Phone numbers, Email addresses, Physical addresses, Social security numbers].'\n",
    "                   'An evaluation agent will review your work and provide you with feedback or tips on how to improve. Understand their feedback and make the necessary changes to your redacted text.'\n",
    "                   'OUTPUT: You must output the redacted text only and not address or respond to any agents directly.',\n",
    "    llm_config=config_list, \n",
    "    human_input_mode='NEVER',\n",
    "    code_execution_config=False\n",
    ")\n",
    "\n",
    "evaluation = autogen.ConversableAgent(\n",
    "    'evaluation-agent',\n",
    "    system_message='OBJECTIVE: You are an evaluation agent tasked with reviewing text to ensure that all personal information has been correctly redacted.'\n",
    "                   'Your job is to verify that only personal information in this LIST: [Names, Phone numbers, Email addresses, Physical addresses, Social security numbers] has been encapsulated with stars (*).'\n",
    "                   'If you find any personal information in the LIST that has not been redacted or if the redaction is inconsistent, you should flag the specific issues and provide feedback.'\n",
    "                   'OUTPUT: Your output must be in points, stating the additional word(s) to be redacted.',\n",
    "    llm_config=config_list,\n",
    "    human_input_mode='NEVER',\n",
    "    code_execution_config=False\n",
    ")\n",
    "\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    'user_proxy', \n",
    "    human_input_mode='NEVER',\n",
    "    code_execution_config=False\n",
    ")\n",
    "\n",
    "chat_outline = {\n",
    "    'message': f'The meeting between Alice Johnson and Bob Williams took place on September 3, 2024. They discussed the upcoming merger between TechCorp and Innovate Inc. During the conversation, Alice mentioned that the final contract would be signed by the end of the month. Bob expressed concerns about the timeline but agreed to proceed with the necessary preparations. Both parties emphasized the importance of confidentiality throughout the process.' \n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_state = 1\n",
    "speakers = []\n",
    "def text_redact_selection_func(speaker: autogen.AssistantAgent, groupchat: autogen.GroupChat):\n",
    "    global conversation_state\n",
    "    if speaker == user_proxy and conversation_state == 1:\n",
    "        conversation_state += 1\n",
    "        speakers.append(text_assistant.name)\n",
    "        return text_assistant\n",
    "    elif speaker == text_assistant and conversation_state == 2:\n",
    "        conversation_state += 1\n",
    "        speakers.append(evaluation.name)\n",
    "        return evaluation\n",
    "    elif speaker == evaluation and conversation_state == 3:\n",
    "        conversation_state += 1\n",
    "        speakers.append(text_assistant.name)\n",
    "        return text_assistant\n",
    "\n",
    "text_redaction_chat = autogen.GroupChat(\n",
    "    agents=[user_proxy, text_assistant, evaluation],\n",
    "    speaker_selection_method=text_redact_selection_func,\n",
    "    messages=[],\n",
    "    max_round=4\n",
    ")\n",
    "\n",
    "text_redaction_manager = autogen.GroupChatManager(\n",
    "    groupchat=text_redaction_chat, llm_config=config_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "The meeting between Alice Johnson and Bob Williams took place on September 3, 2024. They discussed the upcoming merger between TechCorp and Innovate Inc. During the conversation, Alice mentioned that the final contract would be signed by the end of the month. Bob expressed concerns about the timeline but agreed to proceed with the necessary preparations. Both parties emphasized the importance of confidentiality throughout the process.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: assistant\n",
      "\u001b[0m\n",
      "[autogen.oai.client: 09-05 11:01:11] {329} WARNING - Model llama3.1 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33massistant\u001b[0m (to chat_manager):\n",
      "\n",
      "The meeting between *Alice Johnson* and *Bob Williams* took place on September 3, 2024. They discussed the upcoming merger between TechCorp and Innovate Inc. During the conversation, *Alice Johnson* mentioned that the final contract would be signed by the end of the month. *Bob Williams* expressed concerns about the timeline but agreed to proceed with the necessary preparations. Both parties emphasized the importance of confidentiality throughout the process.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: evaluation-agent\n",
      "\u001b[0m\n",
      "[autogen.oai.client: 09-05 11:01:20] {329} WARNING - Model llama3.1 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33mevaluation-agent\u001b[0m (to chat_manager):\n",
      "\n",
      "Based on the provided output, I have identified some areas where additional redaction is required.\n",
      "\n",
      "* The meeting date \"September 3, 2024\" does not contain any personal information that needs to be redacted, but there's no direct reference to names or phone numbers; however, it could still pose a risk if sensitive contracts are signed around this date.\n",
      "* Phone number and email address of *Alice Johnson* and *Bob Williams*: Since they were mentioned as part of the discussion, their corresponding contact details might have been referenced. It would be wise to encapsulate their contact methods with stars (*).\n",
      " \n",
      "Corrected output:\n",
      "\n",
      "The meeting between *Alice Johnson* and *Bob Williams* took place on September 3, 2024. They discussed the upcoming merger between TechCorp and Innovate Inc. During the conversation, *Alice Johnson* mentioned that the final contract would be signed by the end of the month. *Bob Williams* expressed concerns about the timeline but agreed to proceed with the necessary preparations. Both parties emphasized the importance of confidentiality throughout the process.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: assistant\n",
      "\u001b[0m\n",
      "[autogen.oai.client: 09-05 11:01:26] {329} WARNING - Model llama3.1 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33massistant\u001b[0m (to chat_manager):\n",
      "\n",
      "The meeting between *Alice Johnson* and *Bob Williams* took place on September 3, 2024. They discussed the upcoming merger between TechCorp and Innovate Inc. During the conversation, *Alice Johnson* mentioned that the final contract would be signed by the end of the month. *Bob Williams* expressed concerns about the timeline but agreed to proceed with the necessary preparations. Both parties emphasized the importance of confidentiality throughout the process.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "text_redaction_chats = user_proxy.initiate_chat(\n",
    "    text_redaction_manager,\n",
    "    message=chat_outline['message']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redaction Level 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_assistant = autogen.ConversableAgent(\n",
    "    'assistant', \n",
    "    system_message='OBJECTIVE: You are an agent designed to redact personal information from any text provided to you.\\n' \n",
    "                   'Your task is to identify and encapsulate any personal information with stars (*).\\n'\n",
    "                   'IMPORTANT: This includes this LIST: [Names, Company Names, Full Dates, Phone numbers, Email addresses, Physical addresses, Social security numbers].'\n",
    "                   'An evaluation agent will review your work and provide you with feedback or tips on how to improve. Understand their feedback and make the necessary changes to your redacted text.'\n",
    "                   'OUTPUT: You must output the redacted text only and not address or respond to any agents directly.',\n",
    "    llm_config=config_list, \n",
    "    human_input_mode='NEVER',\n",
    "    code_execution_config=False\n",
    ")\n",
    "\n",
    "evaluation = autogen.ConversableAgent(\n",
    "    'evaluation-agent',\n",
    "    system_message='OBJECTIVE: You are an evaluation agent tasked with reviewing text to ensure that all personal information has been correctly redacted.'\n",
    "                   'Your job is to verify that any personal information in this LIST: [Names, Company Names, Full Dates, Months, Phone numbers, Email addresses, Physical addresses, Country names, Social security numbers] has been encapsulated with stars (*).'\n",
    "                   'If you find any personal information in the LIST that has not been redacted, you should flag the specific issues and provide feedback.'\n",
    "                   'OUTPUT: Your output must be in points, stating the additional word(s) to be redacted.',\n",
    "    llm_config=config_list,\n",
    "    human_input_mode='NEVER',\n",
    "    code_execution_config=False\n",
    ")\n",
    "\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    'user_proxy', \n",
    "    human_input_mode='NEVER',\n",
    "    code_execution_config=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_state = 1\n",
    "speakers = []\n",
    "def text_redact_selection_func(speaker: autogen.AssistantAgent, groupchat: autogen.GroupChat):\n",
    "    global conversation_state\n",
    "    if speaker == user_proxy and conversation_state == 1:\n",
    "        conversation_state += 1\n",
    "        speakers.append(text_assistant.name)\n",
    "        return text_assistant\n",
    "    elif speaker == text_assistant and conversation_state == 2:\n",
    "        conversation_state += 1\n",
    "        speakers.append(evaluation.name)\n",
    "        return evaluation\n",
    "    elif speaker == evaluation and conversation_state == 3:\n",
    "        conversation_state += 1\n",
    "        speakers.append(text_assistant.name)\n",
    "        return text_assistant\n",
    "\n",
    "text_redaction_chat = autogen.GroupChat(\n",
    "    agents=[user_proxy, text_assistant, evaluation],\n",
    "    speaker_selection_method=text_redact_selection_func,\n",
    "    messages=[],\n",
    "    max_round=4\n",
    ")\n",
    "\n",
    "text_redaction_manager = autogen.GroupChatManager(\n",
    "    groupchat=text_redaction_chat, llm_config=config_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "The meeting between Alice Johnson and Bob Williams took place on September 3, 2024. They discussed the upcoming merger between TechCorp and Innovate Inc. During the conversation, Alice mentioned that the final contract would be signed by the end of the month. Bob expressed concerns about the timeline but agreed to proceed with the necessary preparations. Both parties emphasized the importance of confidentiality throughout the process.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: assistant\n",
      "\u001b[0m\n",
      "\u001b[33massistant\u001b[0m (to chat_manager):\n",
      "\n",
      "The meeting between *Alice Johnson* and *Bob Williams* took place on September 3, 2024. They discussed the upcoming merger between *TechCorp* and *Innovate Inc*. During the conversation, *Alice* mentioned that the final contract would be signed by the end of the month. *Bob* expressed concerns about the timeline but agreed to proceed with the necessary preparations. Both parties emphasized the importance of confidentiality throughout the process.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: evaluation-agent\n",
      "\u001b[0m\n",
      "[autogen.oai.client: 09-05 11:06:41] {329} WARNING - Model llama3.1 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33mevaluation-agent\u001b[0m (to chat_manager):\n",
      "\n",
      "Feedback: \n",
      "\n",
      "* The date \"September 3, 2024\" contains a full date and should be redacted to \"*September*, **2024**\".\n",
      "* The phrase \"the end of the month\" hints at a specific date within the timeline and could potentially contain personal information; however, it is not clear enough to identify a specific date. Therefore, no additional action is required in this case.\n",
      " \n",
      "Suggestions: \n",
      "\n",
      "* Replace \"September 3, 2024\" with \"*September*, **2024**\".\n",
      " \n",
      "Note that phone numbers, email addresses, physical addresses, and social security numbers are not present in the LIST; however, names (*Alice Johnson*), company names (*TechCorp*, *Innovate Inc*), a vague reference to full dates, and months are appropriately redacted.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: assistant\n",
      "\u001b[0m\n",
      "[autogen.oai.client: 09-05 11:06:46] {329} WARNING - Model llama3.1 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33massistant\u001b[0m (to chat_manager):\n",
      "\n",
      "The meeting between *Alice Johnson* and *Bob Williams* took place on *September*, **2024**. They discussed the upcoming merger between *TechCorp* and *Innovate Inc*. During the conversation, *Alice* mentioned that the final contract would be signed by the end of the month. *Bob* expressed concerns about the timeline but agreed to proceed with the necessary preparations. Both parties emphasized the importance of confidentiality throughout the process.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "text_redaction_chats = user_proxy.initiate_chat(\n",
    "    text_redaction_manager,\n",
    "    message=chat_outline['message']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
